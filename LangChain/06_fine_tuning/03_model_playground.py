import streamlit as st
import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

client = OpenAI()

st.set_page_config(page_title='Fine-Tuning Playground', page_icon='ğŸ›°')

st.title("Fine-Tuning Playground")
st.markdown("ë‚´ê°€ ë§Œë“  **ì»¤ìŠ¤í…€ ëª¨ë¸(fine-tuning)**ê³¼ **ê¸°ë³¸ ëª¨ë¸(Base)**ì˜ ë§íˆ¬ ë¹„êµ")

# ì‚¬ì´ë“œë°” : ëª¨ë¸ ì„¤ì •
with st.sidebar:
    st.header("ëª¨ë¸ ì„¤ì •")

    # Base Model
    base_model = st.text_input("Base Model ID", value='gpt-4o-mini-2024-07-18')

    # Fine-tuned Model
    ft_model = st.text_input("Fine-tuned Model ID",help="í•™ìŠµ ì™„ë£Œ í›„ ë°›ì€ ëª¨ë¸ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    systme_prompt = st.text_area("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸", value="ë„ˆëŠ” íŠ¸ë Œë””í•˜ê³  ì¹œì ˆí•œ ì¸ìŠ¤íƒ€ ë§ˆì¼€í„° ë´‡ì´ì•¼.")

# ì±„íŒ… ê¸°ë¡ ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message['role']):
        st.markdown(message['content'])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# :=(ì›”ëŸ¬ìŠ¤ ì—°ì‚°ì) : ì…ë ¥ê°’ì´ Noneì´ ì•„ë‹ˆë©´ ifë¬¸ ì‹¤í–‰
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” ex) 2026 íŒ¨ì…˜ íŠ¸ëœë“œ ì•Œë ¤ì¤˜"):    

    # ì‚¬ìš©ì ì§ˆë¬¸ì„ í™”ë©´ì— í‘œì‹œ
    st.session_state.messages.append({'role':'user','content':prompt})
    with st.chat_message('user'):
        st.markdown(prompt)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Base Model")
        with st.spinner("ìƒì„± ì¤‘...."):
            try:
                response_base = client.chat.completions.create(
                    model=base_model,
                    messages=[
                        {'role':'system','content':systme_prompt},
                        {'role':'user','content':prompt}
                    ],
                    temperature=0.8
                )
                base_replay = response_base.choices[0].message.content
                st.info(base_replay)
            except Exception as e:
                st.error(f"Error: {e}")
    
    with col2:
        st.subheader("Fine-tuned Model")
        with st.spinner("ìƒì„± ì¤‘...."):
            try:
                response_ft = client.chat.completions.create(
                    model=ft_model,
                    messages=[
                        {'role':'system','content':systme_prompt},
                        {'role':'user','content':prompt}
                    ],
                    temperature=0.8
                )
                ft_replay = response_ft.choices[0].message.content
                st.success(ft_replay)

                st.session_state.messages.append({'role':'assistant','content': ft_replay})
            except Exception as e:
                st.error(f"Error: {e}")