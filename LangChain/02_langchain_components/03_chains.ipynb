{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047e8972",
   "metadata": {},
   "source": [
    "### Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00de6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4efb29",
   "metadata": {},
   "source": [
    "### Simple Chain(기본 체인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4d0dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 수도는 서울(서울특별시)입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser   # 출력 파서(문자열로 변환)\n",
    "\n",
    "# PromptTemplate 생성\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{country}의 수도는 어디인가요?\",\n",
    "    input_variables=['country']     # 사용자가 입력할 변수명 지정\n",
    ")\n",
    "\n",
    "#  LLM Model 생성\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-5-nano\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# OutputParser 생성\n",
    "output_parser = StrOutputParser()   # 모델 출력 결과에서 텍스트 내용(content)만 뽑아주는 파서\n",
    "\n",
    "# Chain 연결 ( 파이프(|) 연산자 사용 )\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "result = chain.invoke(input={\"country\" : '대한민국'})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9402b5",
   "metadata": {},
   "source": [
    "### Sequential Chain(순차 체인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feef32f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분위기가 좋다\n",
      "기운이 들떠 있다\n",
      "오늘 밤 우리는 여기 있다\n",
      "그게 다야\n",
      "그저 멋진 크리스마스 시간일 뿐이야\n",
      "그저 멋진 크리스마스 시간일 뿐이야\n",
      "아이들의 합창단이 노래를 부른다\n",
      "그들은 일년 내내 연습해 왔다\n",
      "딩동, 딩동\n",
      "딩동, 딩동\n",
      "딩동, 딩동\n",
      "동동, 동딩\n",
      "분위기가 좋다\n",
      "기운이 들떠 있다\n",
      "오늘 밤 우리는 여기 있다\n",
      "오, 그게 다야\n",
      "그저 멋진 크리스마스 시간일 뿐이야\n",
      "그저 멋진 크리스마스 시간일 뿐이야\n",
      "오오오, 크리스마스 시간\n"
     ]
    }
   ],
   "source": [
    "# 체인 1: 번역\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "# 모델생성\n",
    "llm = ChatOpenAI(model='gpt-5-nano', temperature=0)\n",
    "\n",
    "input_text = \"\"\"\n",
    "The mood is right\n",
    "The spirit's up\n",
    "We're here tonight\n",
    "And that's enough\n",
    "Simply having a wonderful Christmastime\n",
    "Simply having a wonderful Christmastime\n",
    "The choir of children sing their song\n",
    "They practiced all year long\n",
    "Ding dong, ding dong\n",
    "Ding dong, ding dong\n",
    "Ding dong, ding dong\n",
    "Dong dong, dong ding\n",
    "The mood is right\n",
    "The spirit's up\n",
    "We're here tonight\n",
    "Oh, and that's enough\n",
    "We're simply having a wonderful Christmastime\n",
    "We're simply having a wonderful Christmastime\n",
    "Oh-oh-oh, Christmastime \n",
    "\"\"\"\n",
    "\n",
    "# 번역 프롬프트 생성\n",
    "trans_prompt = PromptTemplate(\n",
    "    template=\"다음의 문장을 한글로 번역하세요 : {text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "# 번역 체인 생성\n",
    "output_parser = StrOutputParser()\n",
    "translation_chain = trans_prompt | llm | output_parser\n",
    "\n",
    "trans_output = translation_chain.invoke(input_text)\n",
    "print(trans_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5dcb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='크리스마스 분위기가 절정인 오늘 밤, 우리는 여기서 멋진 크리스마스 시간을 보내고 있다. 아이들 합창단이 오랜 연습 끝에 노래를 부르며 분위기를 더욱 밝힌다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1021, 'prompt_tokens': 198, 'total_tokens': 1219, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 960, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CqrcgkyGD4JififenRaK2KLBwWMTU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b586e-d694-72e2-a6c0-af7f5622f1fe-0' usage_metadata={'input_tokens': 198, 'output_tokens': 1021, 'total_tokens': 1219, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 960}}\n"
     ]
    }
   ],
   "source": [
    "# 체인 2 : 요약 및 연결\n",
    "from langchain_core.runnables import RunnableSequence   # 여러 Runnable(체인)을 순서대로 실행할 수 있음\n",
    "\n",
    "# 요약 프롬프트 생성\n",
    "sum_prompt = PromptTemplate(\n",
    "    template=\"다음의 글을 짧게 요약하세요 : {text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "# 요약 체인 생성\n",
    "summary_chain = sum_prompt | llm\n",
    "\n",
    "# 체인 연결\n",
    "# 앞의 체인의 출력이 뒤의 체인 입력으로 자동 전달된다.\n",
    "overall_chain = RunnableSequence(translation_chain, summary_chain)\n",
    "\n",
    "final_output = overall_chain.invoke(input_text)\n",
    "print(final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1fda691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='인공지능(AI)은 인간의 지능처럼 문제를 이해하고 판단해 실행하는 능력을 컴퓨터 시스템에 구현하는 기술과 학문 분야를 말합니다.\\n\\n주요 포인트\\n- 목표: 언어 이해, 이미지 인식, 의사 결정, 학습 등 인간이 하는 일을 컴퓨터가 수행하도록 만드는 것.\\n- 좁은 AI vs 일반 AI: 지금 대부분의 AI는 특정 작업에 특화된 “좁은 AI(Narrow AI)”이고, 인간처럼 모든 일을 수행하는 “일반 AI(AGI)”는 아직 없습니다.\\n- 핵심 기술들:\\n  - 머신러닝: 데이터로부터 패턴을 학습해 예측이나 분류를 수행\\n  - 딥러닝: 많은 계층의 인공신경망을 사용해 복잡한 패턴을 더 잘 학습\\n  - 강화학습: 환경과의 상호작용을 통해 최적의 행동을 학습\\n  - 규칙 기반/전통적 AI: 사람이 만든 규칙에 따라 작동하는 방식도 있음\\n- 작동 원리 간단히: 데이터로 모델을 만들고, 새로운 입력이 주어지면 그 모델이 가장 적합한 판단이나 예측을 내림.\\n- 실생활 예시: 스마트폰 음성비서, 추천 시스템(영화/상품 추천), 스팸 필터, 자율주행 자동차, 얼굴 인식 등.\\n\\n주의점과 한계\\n- 데이터 의존성: 데이터 품질과 편향에 따라 결과가 달라질 수 있음\\n- 해석 가능성: 복잡한 모델은 왜 그렇게 판단하는지 설명하기 어려울 때가 있음\\n- 안전·윤리: 프라이버시, 차별, 잘못된 사용 등의 문제 고려 필요\\n\\n필요하시면 더 자세한 예시나 원리(예: 머신러닝 vs 딥러닝 차이, how a chatbot works)도 설명해 드릴게요. 어떤 부분이 궁금한가요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1203, 'prompt_tokens': 32, 'total_tokens': 1235, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 768, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CqtA4nA8krZkP9NJWb67N7wbzmbuD', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b58c9-151f-73e3-9f85-1d7dca86d643-0' usage_metadata={'input_tokens': 32, 'output_tokens': 1203, 'total_tokens': 1235, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 768}}\n"
     ]
    }
   ],
   "source": [
    "# 조건부 체인\n",
    "from langchain_core.runnables import RunnableBranch, RunnablePassthrough\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-5-nano', temperature=0)\n",
    "\n",
    "# 평가 체인\n",
    "grading_prompt = PromptTemplate(\n",
    "    template=\"당신은 냉철한 평가자입니다. 아래 답변을 1~5점으로 평가해주세요:\\n\\n{text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "grading_chain = grading_prompt | llm\n",
    "\n",
    "# 기본 체인\n",
    "default_prompt = PromptTemplate(\n",
    "    template=\"당신은 사용자의 질문에 답하는 친절한 챗봇입니다.\\n\\n{text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "default_chain = default_prompt | llm\n",
    "\n",
    "def grading_routing_fn(input_dict) -> bool:\n",
    "    text = input_dict.get('text', '')\n",
    "    return text.strip().startswith('평가')\n",
    "\n",
    "# RunnableBranch(\n",
    "#     (조건함수, True일때 실행할 체인),\n",
    "#     False일때 실행할 체인\n",
    "# )\n",
    "cond_chain = RunnableBranch(\n",
    "    (grading_routing_fn, grading_chain),\n",
    "    default_chain\n",
    ")\n",
    "\n",
    "# 일반 질문\n",
    "print(cond_chain.invoke(input={'text':'인공지능이 무엇인가요?'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a84ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='점수: 4점\\n\\n설명:\\n- 장점: 인간의 지능이 수행하는 핵심 기능인 문제 이해, 판단/결정, 실행을 컴퓨터 시스템에 구현하는 기술‧학문이라는 고수준 정의가 잘 포착되어 있습니다.\\n- 보완점: 지능의 범위를 다소 모호하게 제시하고 있어, 학습(데이터 기반 학습), 알고리즘(예: 머신러닝/추론), 인지적 기능의 구체성(감지, 추론, 의사결정, 자율성 등)이 빠져 있습니다. 더 구체적으로 확장하면 정의가 더욱 명확해질 것입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 730, 'prompt_tokens': 69, 'total_tokens': 799, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 576, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CqtCmNRnl4y5c0D9nOK9xtw3UgoXa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b58cb-a7b9-7011-8e3a-4bef04d0c0c0-0' usage_metadata={'input_tokens': 69, 'output_tokens': 730, 'total_tokens': 799, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 576}}\n"
     ]
    }
   ],
   "source": [
    "# 평가 질문\n",
    "evaluation_input='평가: 인공지능(AI)은 인간의 지능처럼 문제를 이해하고 판단해 실행하는 능력을 컴퓨터 시스템에 구현하는 기술과 학문 분야를 말합니다.'\n",
    "print(cond_chain.invoke(input={'text': evaluation_input}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c93ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='점수: 1점\\n\\n이유: \"코끼리는 어류이다\"는 과학적으로 잘못된 주장으로, 코끼리는 포유류이다. 따라서 평가 수준이 매우 낮다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 693, 'prompt_tokens': 40, 'total_tokens': 733, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 640, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CqtH9rjtfYVm30FRhIhTPjNuPNhEd', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b58cf-c715-7712-864d-419726365e90-0' usage_metadata={'input_tokens': 40, 'output_tokens': 693, 'total_tokens': 733, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 640}}\n"
     ]
    }
   ],
   "source": [
    "# RunnablePassthrough 활용\n",
    "# {'text': RunnablePassthrough()} : 들어온 문자열을 그대로 'text' 키의 값으로 할당\n",
    "pass_chain = {'text': RunnablePassthrough()} | cond_chain\n",
    "\n",
    "print(pass_chain.invoke('평가: 코끼리는 어류이다.'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
